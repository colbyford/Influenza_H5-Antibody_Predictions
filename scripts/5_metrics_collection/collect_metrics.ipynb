{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Metrics from HADDOCK 3 Experiment Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>antibody_id</th>\n",
       "      <th>antigen_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>haddock_best_cluster</th>\n",
       "      <th>haddock_best_pdb_path</th>\n",
       "      <th>haddock_Nstruc</th>\n",
       "      <th>haddock_Evdw_plus_0.1Eelec</th>\n",
       "      <th>haddock_Evdw_plus_0.1Eelec_sd</th>\n",
       "      <th>haddock_Evdw</th>\n",
       "      <th>...</th>\n",
       "      <th>haddock_AIRviol</th>\n",
       "      <th>haddock_AIRviol_sd</th>\n",
       "      <th>haddock_dihedviol</th>\n",
       "      <th>haddock_dihedviol_sd</th>\n",
       "      <th>haddock_BSA</th>\n",
       "      <th>haddock_BSA_sd</th>\n",
       "      <th>haddock_score</th>\n",
       "      <th>haddock_score_sd</th>\n",
       "      <th>haddock_prodigy_deltaG_kcalpermol</th>\n",
       "      <th>haddock_prodigy_dissociation_constant_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_5A3I</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id antibody_id antigen_id  submitted  haddock_best_cluster  \\\n",
       "0     TEST_5A3I         NaN        NaN        NaN                   NaN   \n",
       "\n",
       "   haddock_best_pdb_path  haddock_Nstruc  haddock_Evdw_plus_0.1Eelec  \\\n",
       "0                    NaN             NaN                         NaN   \n",
       "\n",
       "   haddock_Evdw_plus_0.1Eelec_sd  haddock_Evdw  ...  haddock_AIRviol  \\\n",
       "0                            NaN           NaN  ...              NaN   \n",
       "\n",
       "   haddock_AIRviol_sd  haddock_dihedviol  haddock_dihedviol_sd  haddock_BSA  \\\n",
       "0                 NaN                NaN                   NaN          NaN   \n",
       "\n",
       "   haddock_BSA_sd  haddock_score  haddock_score_sd  \\\n",
       "0             NaN            NaN               NaN   \n",
       "\n",
       "   haddock_prodigy_deltaG_kcalpermol  haddock_prodigy_dissociation_constant_M  \n",
       "0                                NaN                                      NaN  \n",
       "\n",
       "[1 rows x 27 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in Experiments worksheet\n",
    "experiments = pd.read_excel('../../Experiments.xlsx', sheet_name='Experiments').head(0)\n",
    "## For testing...\n",
    "experiments = experiments.append({'experiment_id': 'TEST_5A3I'}, ignore_index=True)\n",
    "\n",
    "# experiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create empty dataframe to store results\n",
    "metrics_df = pd.DataFrame(columns=['experiment_id', 'cluster_rank', 'cluster_id', 'n', 'under_eval',\n",
    "                                   'score', 'score_std', 'irmsd', 'irmsd_std',\n",
    "                                   'fnat', 'fnat_std', 'lrmsd', 'lrmsd_std', 'dockq', 'dockq_std',\n",
    "                                   'air', 'air_std', 'bsa', 'bsa_std',\n",
    "                                   'desolv', 'desolv_std', 'elec', 'elec_std',\n",
    "                                   'total', 'total_std', 'vdw', 'vdw_std',\n",
    "                                   'caprieval_rank', 'best_pdb_path'])\n",
    "\n",
    "# metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting metrics for experiment: TEST_5A3I\n"
     ]
    }
   ],
   "source": [
    "for index, experiment in experiments.iterrows():\n",
    "    experiment_id = experiment['experiment_id']\n",
    "    print(f\"Getting metrics for experiment: {experiment_id}\")\n",
    "\n",
    "    ## Check if the output/ directory exists\n",
    "    outputs_dir = f\"../../data/experiments/{experiment_id}/output/analysis/6_caprieval_analysis\"\n",
    "    if os.path.exists(outputs_dir):\n",
    "        ## Read in the cluster metrics .tsv file, skipping rows that start with # character\n",
    "        cluster_metrics_file = f\"{outputs_dir}/capri_clt.tsv\"\n",
    "        metrics_df_iter = pd.read_csv(cluster_metrics_file, sep='\\t', comment='#')\n",
    "        ## Filter to the row with the lowest vdw score\n",
    "        metrics_df_iter_best = metrics_df_iter[metrics_df_iter['vdw'] == metrics_df_iter['vdw'].min()]\n",
    "        best_cluster = metrics_df_iter_best.iloc[0]['cluster_id']\n",
    "        \n",
    "        ## Read in the individual metrics file\n",
    "        ss_metrics_file = f\"{outputs_dir}/capri_ss.tsv\"\n",
    "        ss_df_iter = pd.read_csv(ss_metrics_file, sep='\\t', comment='#')\n",
    "        ## Filter to the rows with the best cluster\n",
    "        ss_df_iter = ss_df_iter[ss_df_iter['cluster-id'] == best_cluster]\n",
    "        ## Find the best PDB with the lowest vdw score\n",
    "        ss_df_iter_best = ss_df_iter[ss_df_iter['vdw'] == ss_df_iter['vdw'].min()].iloc[0]\n",
    "\n",
    "        ## Add the best PDB path to the metrics dataframe\n",
    "        metrics_df_iter_best['best_pdb_path'] = ss_df_iter_best['model']\n",
    "        metrics_df_iter_best['experiment_id'] = experiment_id\n",
    "        metrics_df = metrics_df.append(metrics_df_iter_best)\n",
    "\n",
    "    else:\n",
    "        print(f\"\\tNo output/ directory found.\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>cluster_rank</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>n</th>\n",
       "      <th>under_eval</th>\n",
       "      <th>score</th>\n",
       "      <th>score_std</th>\n",
       "      <th>irmsd</th>\n",
       "      <th>irmsd_std</th>\n",
       "      <th>fnat</th>\n",
       "      <th>...</th>\n",
       "      <th>desolv</th>\n",
       "      <th>desolv_std</th>\n",
       "      <th>elec</th>\n",
       "      <th>elec_std</th>\n",
       "      <th>total</th>\n",
       "      <th>total_std</th>\n",
       "      <th>vdw</th>\n",
       "      <th>vdw_std</th>\n",
       "      <th>caprieval_rank</th>\n",
       "      <th>best_pdb_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_5A3I</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>15.923</td>\n",
       "      <td>6.469</td>\n",
       "      <td>8.819</td>\n",
       "      <td>7.485</td>\n",
       "      <td>0.369</td>\n",
       "      <td>...</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.176</td>\n",
       "      <td>-284.209</td>\n",
       "      <td>31.112</td>\n",
       "      <td>1065.848</td>\n",
       "      <td>91.206</td>\n",
       "      <td>-73.191</td>\n",
       "      <td>6.087</td>\n",
       "      <td>1</td>\n",
       "      <td>../../5_mdref/mdref_1.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_5A3I</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>10</td>\n",
       "      <td>-</td>\n",
       "      <td>15.923</td>\n",
       "      <td>6.469</td>\n",
       "      <td>8.819</td>\n",
       "      <td>7.485</td>\n",
       "      <td>0.369</td>\n",
       "      <td>...</td>\n",
       "      <td>3.63</td>\n",
       "      <td>3.176</td>\n",
       "      <td>-284.209</td>\n",
       "      <td>31.112</td>\n",
       "      <td>1065.848</td>\n",
       "      <td>91.206</td>\n",
       "      <td>-73.191</td>\n",
       "      <td>6.087</td>\n",
       "      <td>1</td>\n",
       "      <td>../../5_mdref/mdref_1.pdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment_id cluster_rank cluster_id   n under_eval   score  score_std  \\\n",
       "0     TEST_5A3I            -          -  10          -  15.923      6.469   \n",
       "0     TEST_5A3I            -          -  10          -  15.923      6.469   \n",
       "\n",
       "   irmsd  irmsd_std   fnat  ...  desolv  desolv_std     elec  elec_std  \\\n",
       "0  8.819      7.485  0.369  ...    3.63       3.176 -284.209    31.112   \n",
       "0  8.819      7.485  0.369  ...    3.63       3.176 -284.209    31.112   \n",
       "\n",
       "      total  total_std     vdw  vdw_std  caprieval_rank  \\\n",
       "0  1065.848     91.206 -73.191    6.087               1   \n",
       "0  1065.848     91.206 -73.191    6.087               1   \n",
       "\n",
       "               best_pdb_path  \n",
       "0  ../../5_mdref/mdref_1.pdb  \n",
       "0  ../../5_mdref/mdref_1.pdb  \n",
       "\n",
       "[2 rows x 29 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
